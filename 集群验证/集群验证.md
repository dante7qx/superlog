## 集群验证

### 一. 环境准备

- 操作系统：centos7.9（最小安装，虚拟机2C、4G、50G）

  | 服务器 | 主机名 | 操作系统                 | IP             |
  | ------ | ------ | ------------------------ | -------------- |
  | node1  | node1  | centos7.9（2C、4G、50G） | 172.16.125.181 |
  | node2  | node2  | centos7.9（2C、4G、50G） | 172.16.125.182 |
  | node3  | node3  | centos7.9（2C、4G、50G） | 172.16.125.183 |
  | node4  | node4  | centos7.9（2C、4G、50G） | 172.16.125.184 |
  | node5  | node5  | centos7.9（2C、4G、50G） | 172.16.125.185 |
  | node6  | node6  | centos7.9（2C、4G、50G） | 172.16.125.186 |

- 配置静态IP

  为每一台服务器配置静态IP（防止虚拟机IP变化）

  ```shell
  cd /etc/sysconfig/network-scripts
  ## 找到当前网卡，配置静态IP
  vi ifcfg-ens33
  
  ## 修改内容，IPADDR 修改为 172.16.125.[181 182 183 184 185 186]
  BOOTPROTO=static
  ONBOOT=yes
  IPADDR=172.16.125.[181 182 183 184 185 186]
  NETMASK=255.255.255.0
  GATEWAY=172.16.125.2
  DNS1=8.8.8.8
  DNS2=114.114.114.114
  
  ## 重启网络服务
  systemctl restart network
  
  ## 测试，若有延迟，可以调换DNS的顺序，114在前、8在后
  ping baidu.com
  ## 查看IP
  ip a
  ```

- 配置主机名、Hosts

  ```shell
  ## 181 - 186
  hostnamectl set-hostname node [1 ... 6]
  systemctl restart network
  
  ## 三台服务器上操作
  vi /etc/hosts
  ## 添加内容
  172.16.125.181 node1
  172.16.125.182 node2
  172.16.125.183 node3
  172.16.125.184 node4
  172.16.125.185 node5
  172.16.125.186 node6
  ```

- 配置免密登录

  ```shell
  ## 每台机器上执行
  ssh-keygen -t rsa -P ''
  cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
  chmod 600 ~/.ssh/authorized_keys
  
  cat ~/.ssh/id_rsa.pub | ssh root@node1 'cat - >> ~/.ssh/authorized_keys'
  cat ~/.ssh/id_rsa.pub | ssh root@node2 'cat - >> ~/.ssh/authorized_keys'
  cat ~/.ssh/id_rsa.pub | ssh root@node3 'cat - >> ~/.ssh/authorized_keys'
  cat ~/.ssh/id_rsa.pub | ssh root@node4 'cat - >> ~/.ssh/authorized_keys'
  cat ~/.ssh/id_rsa.pub | ssh root@node5 'cat - >> ~/.ssh/authorized_keys'
  cat ~/.ssh/id_rsa.pub | ssh root@node6 'cat - >> ~/.ssh/authorized_keys'
  ```

### 二. 软件安装

#### 1. JDK

```shell
## 在每一台node上
tar -zxvf /opt/software/jdk-17.0.10_linux-x64_bin.tar.gz
mv /opt/software/jdk-17.0.10 /usr/local/
ln -s /usr/local/jdk-17.0.10 /usr/local/java

## 配置JAVA_HOME
vi ~/.bashrc

## JDK
export JAVA_HOME=/usr/local/java
export JRE_HOME=${JAVA_HOME}/jre
export CLASSPATH=.:${JAVA_HOME}/lib:${JRE_HOME}/lib
export PATH=${JAVA_HOME}/bin:$PATH


## 配置生效
source ~/.bashrc
```

### 三. Kafka集群

本例使用`kafka_2.13-3.7.0`，分别基于`Zookeeper`和`KRaft`进行安装。集群规模：node1、node2、node3。

#### 1. Zookeeper 方式

kafka2.8.0版本后使用了新的Raft模式来搭建集群，也就是从这个版本后kafka在逐步放弃zookeeper。本文以kafka3.7.0自带的zookeeper模式来搭建生产环境集群。[参考链接](https://developer.aliyun.com/article/1417704?spm=a2c6h.12873639.article-detail.19.764d46d9ymwelN&scm=20140722.ID_community@@article@@1417704._.ID_community@@article@@1417704-OR_rec-V_1-RL_community@@article@@1435347)

在 node1、node2、node3 上进行操作。

- 开放端口 2181、2888、3888、9092

```shell
firewall-cmd --permanent --zone=public --add-port=2181/tcp
firewall-cmd --permanent --zone=public --add-port=2888/tcp
firewall-cmd --permanent --zone=public --add-port=3888/tcp
firewall-cmd --permanent --zone=public --add-port=9092/tcp
firewall-cmd --reload
```

- 下载Kafka，并解压到 `/usr/local/kafka`下，设置 `KAFKA_HOME`

```shell
tar -zxvf kafka_2.13-3.7.0.tgz
mv kafka_2.13-3.7.0 /usr/local/kafka

## 设置环境变量
export KAFKA_HOME=/usr/local/kafka
export PATH=$PATH:$KAFKA_HOME/bin
```

- 配置 `Zookeeper`（/usr/local/kafka/conf/zookeeper.properties）

```properties
dataDir=/usr/local/kafka/data/zkdata
dataLogDir=/usr/local/kafka/data/zklog
clientPort=2181
maxClientCnxns=100
tickTime=2000
initLimit=20
syncLimit=10
server.1=node1:2888:3888
server.2=node2:2888:3888
server.3=node3:2888:3888
```

- 在zookeeper数据所在目录：/usr/local/kafka/data/zkdata，建立myid文件，并根据server.id填写id

```shell
## node1
echo 1 > /usr/local/kafka/data/zkdata/myid 
## node2
echo 2 > /usr/local/kafka/data/zkdata/myid 
## node3
echo 3 > /usr/local/kafka/data/zkdata/myid 
```

- 配置 `Kafka`（/usr/local/kafka/conf/server.properties）

```properties
## 全局唯一（node1 -> 1, node2 -> 2, node3 -> 3）
broker.id=1	
listeners=PLAINTEXT://node1:9092
advertised.listeners=PLAINTEXT://node1:9092
log.dirs=/usr/local/kafka/data/zk-kafka-logs
zookeeper.connect=node1:2181,node2:2181,node3:2181
```

> - **listeners**：这个配置项指定了 Kafka Broker 监听的网络接口和端口。它定义了 Broker 之间通信的地址。除了用于客户端连接，它还用于 Broker 之间的通信，例如复制数据、ISR（In-Sync Replicas）同步等。这也是 Kafka 集群内部通信的地址。
> - **advertised.listeners**：这个配置项指定了 Kafka Broker 对外公布的地址，即客户端连接地址。它告诉客户端应该使用什么地址来连接到 Kafka Broker。这在 Kafka Broker 与客户端之间存在网络隔离或 NAT 环境时特别有用。如果 Broker 的实际地址与客户端所在网络环境不匹配（例如 Broker 在 Docker 容器中，客户端在主机上），那么就需要使用 `advertised.listeners` 来指定客户端连接地址。
>
> 所以，`listeners` 主要用于 Kafka 集群内部通信，而 `advertised.listeners` 主要用于客户端连接。

- `kafka` 配置说明

| key                                                | value                                                        |
| -------------------------------------------------- | ------------------------------------------------------------ |
| delete.topic.enable=true                           | 是否允许删除topic，默认false不能手动删除                     |
| broker.id=0                                        | 当前机器在集群中的唯一标识，和zookeeper的myid性质一样        |
| listeners = PLAINTEXT://192.168.100.151:9092       | 当前kafka服务侦听的地址和端口，端口默认是9092                |
| num.network.threads=3                              | 这个是borker进行网络处理的线程数                             |
| num.io.threads=8                                   | 这个是borker进行I/O处理的线程数                              |
| socket.send.buffer.bytes=102400                    | 发送缓冲区buffer大小，数据不是一下子就发送的，先会存储到缓冲区到达一定的大小后在发送，能提高性能 |
| socket.receive.buffer.bytes=102400                 | kafka接收缓冲区大小，当数据到达一定大小后在序列化到磁盘      |
| socket.request.max.bytes=104857600                 | 这个参数是向kafka请求消息或者向kafka发送消息的请请求的最大数，这个值不能超过java的堆栈大小 |
| log.dirs=                                          | 消息日志存放的路径                                           |
| num.partitions=1                                   | 默认的分区数，一个topic默认1个分区数                         |
| num.recovery.threads.per.data.dir=1                | 每个数据目录用来日志恢复的线程数目                           |
| log.retention.hours=168                            | 默认消息的最大持久化时间，168小时，7天                       |
| log.segment.bytes=1073741824                       | 这个参数是：因为kafka的消息是以追加的形式落地到文件，当超过这个值的时候，kafka会新起一个文件 |
| log.retention.check.interval.ms=300000             | 每隔300000毫秒去检查上面配置的log失效时间                    |
| log.cleaner.enable=false                           | 是否启用log压缩，一般不用启用，启用的话可以提高性能          |
| zookeeper.connect=node1:2181,node2:2181,node3:2181 | 设置zookeeper的连接端口                                      |
| zookeeper.connection.timeout.ms=6000               | 设置zookeeper的连接超时时间                                  |

- 启动服务

```shell
## 三台先启动Zookeeper
zookeeper-server-start.sh -daemon ${KAFKA_HOME}/config/zookeeper.properties

## 三台启动Kafka
kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties
```

- 编写启动脚本

```shell
touch /usr/local/kafka/kafka-run.sh
chmod +x /usr/local/kafka/kafka-run.sh
```

```shell
#!/bin/bash

if [ $# -lt 1 ]
then
	echo "Please input args, start、stop、status"
	exit;
fi

case $1 in
"start")
	echo "=============================== 启动集群 ==============================="
	
	echo "------------------------------- 启动 zookeeper -------------------------------"
	for host in node1 node2 node3
	do
      echo "------------------------------- 启动 $host -------------------------------"
      ssh $host "zookeeper-server-start.sh -daemon ${KAFKA_HOME}/config/zookeeper.properties"
	done
	sleep 2
	echo "------------------------------- 启动 kafka -------------------------------"
	for host in node1 node2 node3
	do
      echo "------------------------------- 启动 $host -------------------------------"    
      ssh $host "kafka-server-start.sh -daemon ${KAFKA_HOME}/config/server.properties"
	done
;;
"stop")
	echo "=============================== 停止集群 ==============================="
	echo "------------------------------- 停止 kafka -------------------------------"
	for host in node1 node2 node3
  do
      echo "------------------------------- 停止 $host -------------------------------"
      ssh $host kafka-server-stop.sh
  done
  
  echo "------------------------------- 停止 zookeeper -------------------------------"
	for host in node1 node2 node3
  do
      echo "------------------------------- 停止 $host -------------------------------"
      ssh $host zookeeper-server-stop.sh
  done
;;
"status")
	echo "=============================== 集群状态 ==============================="
	for host in node1 node2 node3
	do
      echo "------------------------------- $host -------------------------------"
      ssh $host jps
	done
;;
*)
	echo "Input Args Error, Please input args, start、stop、status"
;;
esac
```

#### 2. KRaft 方式

参考：https://blog.csdn.net/WonderThink/article/details/123582097

#### 3. 可视化工具

https://www.kafkatool.com/download.html